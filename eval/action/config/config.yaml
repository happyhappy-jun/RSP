defaults:
  - dataset: imagenet1k
  - model: vit_large
  - hydra/launcher: basic
  - _self_

# Wandb Configuration
wandb:
  project: "rsp-linear"
  entity: happyhappy  # your wandb username/entity
  group: ${dataset.name}  # group by dataset
  name: ${model.name}_${dataset.name}  # descriptive run name
  tags: ["linear_probe", "${model.name}", "${dataset.name}"]
  mode: "online"  # set to "disabled" to disable wandb

hydra:
  job:
    chdir: True
  run:
    dir: ${output_dir}
  output_subdir: null

# Training parameters
batch_size: 512
epochs: 90
accum_iter: 1

# Learning rate parameters
lr: null
blr: 0.1
min_lr: 0.0
warmup_epochs: 10

# Output parameters
output_dir: './output_dir'
log_dir: ${output_dir}

# Runtime parameters
device: cuda
seed: 0
resume: ''
start_epoch: 0
eval: false
dist_eval: false
num_workers: 12
prefetch_factor: 4
pin_mem: true

# Distributed training parameters
world_size: -1  # 2 GPUs per task
local_rank: -1
dist_on_itp: false
dist_url: env://
rank: 0
gpu: null  # Let Hydra manage GPU assignment
distributed: true
dist_backend: 'nccl'

